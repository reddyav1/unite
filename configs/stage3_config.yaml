aa: rand-m7-n4-mstd0.5-inc1
auto_resume: false
batch_size: 2
batch_size_val: 32
checkpoint_num: 0
checkpoints_enabled: false
class_loss_src_ratio: 1.0e-12
clip_decoder_embed_dim: 768
clip_decoder_type: SA_Decoder
clip_grad: null
clip_input_resolution: 224
clip_loss_data: target
clip_loss_ratio: 1.0
clip_loss_type: l2
clip_norm_type: l2
clip_output_dim: 512
clip_return_attn: true
clip_return_interval: 1.0
clip_return_layers:
- 6
clip_student_return_interval: 1.0
clip_teacher: clip_b16
color_jitter: 0.0
crop_pct: null
data_set: Kinetics_sparse
decoder_depth: 4
device: cuda
disable_wandb: false
dist_backend: nccl
dist_on_itp: false
dist_url: env://
distributed: true
drop_path: 0.1
epochs: 50
flip: 'True'
freeze_clip_decoders: false
gpu: 0
imagenet_default_mean_and_std: true
initial_validation: true
input_size: 224
layer_decay: 0.75
local_rank: -1
log_freq: 10
lr: 1.0e-5
mask_ratio: 0.8
mask_type: attention
min_lr: 1.0e-05
model: adaptation_umt_base_patch16_224
model_key: model|module
momentum: 0.9
nb_classes: 12
normlize_target: true
num_frames: 8
num_sample: 1
num_segments: 8
num_workers: 6
opt: adamw
opt_betas:
- 0.9
- 0.95
opt_eps: 1.0e-08
pin_mem: true
prefix: ''
pseudolabel_threshold: 0.0
rank: 0
resume: ''
sampling_rate: 0
save_ckpt_freq: 1000
seed: 0
short_side_size: 224
split: ','
src_classifier_type: linear
start_epoch: 0
student_prefix: ''
target_only_classification: false
test_best: true
test_num_crop: 3
test_num_segment: 5
train_fraction: 1.0
train_interpolation: bicubic
tubelet_size: 1
unmasked_classification: true
use_checkpoint: false
use_cls_token: false
use_decord: true
use_learnable_pos_emb: false
val_interval: 1
warmup_epochs: 0
warmup_lr: 1.0e-06
warmup_steps: -1
weight_decay: 0.05
weight_decay_end: null
world_size: 4
reprob: 0.25
remode: pixel
recount: 1
train_interpolation: bicubic
return_aug_for_val: true
full_oracle: false
conf_weighted_loss: true
class_loss_tgt_ratio: 1.0
train_masked: true
masking_type: clip_attention
selection_strategy: clip_matchORconf